# CS6150_Advanced_Algorithm

## Data extracting
We use one dataset, image, in our evaluation, following Section 5.1 of the paper. The dataset is extracted from the Caltech101, which is not included in this repository. The full extracted dataset is also not included, since it is too big. A small and a medium size dataset is included in the `.\data` directory.

This repository is ignoring the original data files. If you are interested on the original data or the data extracting process, you can follow these steps:
1. Download the file [101_ObjectCategories.tar.gz](http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz);
2. Extract its contents into `.\data\original\`.
3. Make sure you can find `image_0001.jpg` under `.\data\original\101_ObjectCategories\accordion\`.
4. Install Python packages [opencv-contrib](https://anaconda.org/michael_wild/opencv-contrib) if you don't have it. An alternative distribution is `pip install opencv-contrib-python` (I have not tried this.)
5. Run `python detect_images.py` will get `.\data\Caltech101_small.npy`. `.\data\Caltech101_medium.npy` is generated by `python detect_images.py -o data/Caltech101_medium -l 100`. Run `python detect_images.py -h` for other options. `detect_images.py` is multiprocessing, I kept its prototype `data_from_Caltech101.py` for a record.
6. `data_from_Caltech101.py` is the prototype of `detect_images.py`, it simply process all the images (if you have them in the right directory) in one processor. It will need one and a half hours to finish. You can get the same result by running `python detect_images.py -o data/Caltech101_full -l all`, this is much faster because multiprocessing. `data_from_Caltech101.py` is here just for a record, it is easier to understand the code.
